const express = require('express');
const cors = require('cors');
const AdvancedStatistics = require('./utils/advancedStats');
const axios = require('axios');
const mongoose = require('mongoose');
const path = require('path');
const dotenv = require('dotenv');
const fs = require('fs');
const multer = require('multer');
const XLSX = require('xlsx');
const statisticalAnalysis = require('./utils/statisticalAnalysis');
const { detectAvailableMetrics, detectIndustryType, generateIndustryMetrics } = require('./utils/schemaAwareAnalysis');
const { generateSQLDocumentation, formatSQLForDisplay } = require('./utils/sqlDocumentation');
const { buildStatisticalPromptAddition } = require('./utils/statisticalValidator');
const { mapColumnNames } = require('./utils/columnMapper');
const { validateDataIntegrity, canCalculateGrowth, canPerformStatistics, canForecast } = require('./utils/productionValidator');
const { generateValidatedSQL } = require('./utils/sqlGenerator');
const pdf = require('pdf-parse');
const mammoth = require('mammoth');

require('dotenv').config();

// ============================================
// INJECT FIREBASE CONFIG AT RUNTIME
// ============================================
const createFirebaseConfig = () => {
  const buildPath = path.join(__dirname, '..', 'frontend', 'build');
  
  console.log('ðŸ” [CONFIG] Build path:', buildPath);
  console.log('ðŸ” [CONFIG] Build path exists:', fs.existsSync(buildPath));
  
  // Create build directory if it doesn't exist
  if (!fs.existsSync(buildPath)) {
    console.log('âš ï¸ [CONFIG] Build directory not found, creating it...');
    fs.mkdirSync(buildPath, { recursive: true });
  }
  
  // Create the Firebase config object
  const firebaseConfig = {
    apiKey: process.env.REACT_APP_FIREBASE_API_KEY || '',
    authDomain: process.env.REACT_APP_FIREBASE_AUTH_DOMAIN || '',
    projectId: process.env.REACT_APP_FIREBASE_PROJECT_ID || '',
    storageBucket: process.env.REACT_APP_FIREBASE_STORAGE_BUCKET || '',
    messagingSenderId: process.env.REACT_APP_FIREBASE_MESSAGING_SENDER_ID || '',
    appId: process.env.REACT_APP_FIREBASE_APP_ID || '',
    measurementId: process.env.REACT_APP_FIREBASE_MEASUREMENT_ID || ''
  };

  // Create the config.js file
  const configJsContent = `window.firebaseConfig = ${JSON.stringify(firebaseConfig, null, 2)};`;
  const configJsPath = path.join(buildPath, 'config.js');
  
  console.log('ðŸ” [CONFIG] Creating Firebase config file at:', configJsPath);
  fs.writeFileSync(configJsPath, configJsContent);
  console.log('âœ… Firebase config injected at runtime');
  
  // Also create env-config.js as a backup
  const envConfigContent = `window.ENV = ${JSON.stringify({
    REACT_APP_API_URL: '',
    ...firebaseConfig
  }, null, 2)};`;
  fs.writeFileSync(path.join(buildPath, 'env-config.js'), envConfigContent);
  console.log('âœ… Environment config created');
};

// Call this before starting the server
try {
  createFirebaseConfig();
} catch (error) {
  console.error('âŒ Failed to create Firebase config:', error.message);
  console.error('Stack:', error.stack);
}

// ============================================
// SECURITY UTILITIES
// ============================================

// ============================================
// CURRENCY FORMATTING (PREVENTS 10Ã— BUG)
// ============================================

/**
 * Format currency correctly for Indian notation
 * Prevents â‚¹3.27L being shown as â‚¹32.7L
 */
const formatIndianCurrency = (amount) => {
  if (!amount || isNaN(amount)) return 'â‚¹0';
  
  const absAmount = Math.abs(amount);
  
  if (absAmount >= 10000000) {
    // Crores (1 crore = 1,00,00,000)
    return `â‚¹${(amount / 10000000).toFixed(2)} crores`;
  } else if (absAmount >= 100000) {
    // Lakhs (1 lakh = 1,00,000)
    return `â‚¹${(amount / 100000).toFixed(2)} lakhs`;
  } else if (absAmount >= 1000) {
    return `â‚¹${amount.toLocaleString('en-IN')}`;
  } else {
    return `â‚¹${amount.toFixed(2)}`;
  }
};

/**
 * Dual format for absolute clarity
 */
const formatCurrencyDual = (amount) => {
  if (!amount || isNaN(amount)) return 'â‚¹0';
  
  const formatted = amount.toLocaleString('en-IN');
  
  if (amount >= 10000000) {
    const crores = (amount / 10000000).toFixed(2);
    return `â‚¹${formatted} (â‚¹${crores} crores)`;
  } else if (amount >= 100000) {
    const lakhs = (amount / 100000).toFixed(2);
    return `â‚¹${formatted} (â‚¹${lakhs} lakhs)`;
  } else {
    return `â‚¹${formatted}`;
  }
};

// Sanitize CSV to prevent formula injection
const sanitizeCSV = (csvData) => {
  return csvData
    .split('\n')
    .map(line => {
      // Remove formula injection characters at start
      if (/^[=+\-@\t\r]/.test(line)) {
        return "'" + line; // Prefix with quote to neutralize
      }
      return line;
    })
    .join('\n');
};

// Validate file MIME type (not just extension)
const validateFileType = async (filePath, allowedTypes) => {
  try {
    const FileType = (await import('file-type')).default;
    const fileTypeResult = await FileType.fromFile(filePath);
    
    if (!fileTypeResult) {
      // Some valid files don't have detectable MIME (like plain text CSV)
      return true;
    }
    
    return allowedTypes.includes(fileTypeResult.mime);
  } catch (error) {
    console.error('File type validation error:', error);
    return false;
  }
};

// Sanitize filename to prevent path traversal
const sanitizeFilename = (filename) => {
  return filename
    .replace(/[^a-zA-Z0-9._-]/g, '_') // Remove special chars
    .substring(0, 255); // Limit length
};

// Sanitize MongoDB query parameters
const sanitizeMongoInput = (value) => {
  if (typeof value !== 'string') {
    return undefined;
  }
  // Remove MongoDB operators
  return value.replace(/[${}]/g, '');
};

// Validate against whitelist
const validateDataType = (dataType) => {
  const allowedTypes = ['sales', 'marketing', 'fintech', 'ecommerce', 'saas', 'business'];
  return allowedTypes.includes(dataType) ? dataType : undefined;
};
const app = express();
app.set('trust proxy', 1);

const PORT = process.env.PORT || 7860;
// Middleware
const rateLimit = require('express-rate-limit');
const timeout = require('connect-timeout');

app.use(timeout('60s')); // 60 second timeout
app.use((req, res, next) => {
  if (!req.timedout) next();
});

const allowedOrigins = process.env.NODE_ENV === 'production'
? [
      process.env.FRONTEND_URL,
      'https://insightai-app-v2.firebaseapp.com'
    ].filter(Boolean)
  : [
      'http://localhost:3000',
      'http://localhost:5000',
      'http://127.0.0.1:3000',
      'http://localhost:7860',
      'http://127.0.0.1:7860'
    ];
const corsOptions = {
  origin: function (origin, callback) {
    // Allow requests with no origin (mobile apps, Postman, etc.)
    if (!origin) return callback(null, true);
    
    // Check exact matches
    if (allowedOrigins.includes(origin)) {
      return callback(null, true);
    }
    
    // Allow all Render domains in production
    if (process.env.NODE_ENV === 'production' && origin && origin.includes('.onrender.com')) {
      return callback(null, true);
    }
    
    console.warn('âš ï¸ Blocked CORS request from:', origin);
    callback(new Error('Not allowed by CORS'));
  },
  credentials: true, // Allow cookies
  optionsSuccessStatus: 200,
  methods: ['GET', 'POST', 'PUT', 'DELETE', 'OPTIONS'],
  allowedHeaders: ['Content-Type', 'Authorization']
};

app.use(cors(corsOptions));

// Handle preflight requests
app.options('*', cors(corsOptions));
app.use(express.json({ limit: '50mb' }));
// General API rate limit
const limiter = rateLimit({
  windowMs: 15 * 60 * 1000, // 15 minutes
  max: 100,
  message: 'Too many requests, please try again later.',
  standardHeaders: true,
  legacyHeaders: false,
});

app.use('/api/', limiter);

// Stricter limit for AI endpoints
const aiLimiter = rateLimit({
  windowMs: 60 * 1000, // 1 minute
  max: 10,
  message: 'AI request limit exceeded. Please wait.',
  standardHeaders: true,
  legacyHeaders: false,
});

app.use('/api/analyze', aiLimiter);
app.use('/api/parse-data', aiLimiter);
app.use('/api/compare-analysis', aiLimiter);

// Stricter limit for file uploads (resource intensive)
const uploadLimiter = rateLimit({
  windowMs: 60 * 1000, // 1 minute
  max: 5, // Only 5 uploads per minute
  message: 'Too many file uploads. Please wait before uploading again.',
  standardHeaders: true,
  legacyHeaders: false,
});

// Environment variables
const GROQ_API_KEY = process.env.GROQ_API_KEY?.trim();
const MONGODB_URI = process.env.MONGODB_URI?.trim();
const GROQ_API_URL = 'https://api.groq.com/openai/v1/chat/completions';

// Validate GROQ API key format
if (GROQ_API_KEY && !GROQ_API_KEY.startsWith('gsk_')) {
  console.error('âŒ GROQ_API_KEY appears to be invalid. Should start with "gsk_"');
  console.error('   Current key starts with:', GROQ_API_KEY.substring(0, 4));
}

if (!GROQ_API_KEY) {
  console.error('âŒ GROQ_API_KEY is missing! AI features will not work.');
  console.error('   Please add GROQ_API_KEY to your .env file');
}

// âœ… SECURE: No key details exposed
console.log('ðŸ”‘ GROQ_API_KEY:', GROQ_API_KEY ? 'âœ… Configured' : 'âŒ Missing');
console.log('ðŸ”‘ MONGODB_URI:', MONGODB_URI ? 'âœ… Configured' : 'âŒ Missing');
// Secure error handler - hides details in production
// âœ… SECURE: Never expose internal errors
const handleError = (res, error, customMessage = 'An error occurred') => {
  // Log full error server-side only
  console.error('âŒ Error Details [INTERNAL]:', {
    message: error.message,
    stack: process.env.NODE_ENV === 'development' ? error.stack : undefined,
    timestamp: new Date().toISOString()
  });
  
  // NEVER send internal errors to client
  res.status(500).json({ 
    success: false, 
    error: customMessage // Always use generic message
  });
};

// ============================================
// MONGODB CONNECTION WITH AUTO-RETRY
// ============================================
let isConnecting = false;

const connectDB = async () => {
  if (isConnecting) return;
  
  isConnecting = true;
  
  try {
    await mongoose.connect(MONGODB_URI, {
      serverSelectionTimeoutMS: 5000,
      socketTimeoutMS: 45000,
    });
    
    console.log('âœ… MongoDB Connected Successfully');
    console.log(`ðŸ“Š Database: ${mongoose.connection.db.databaseName}`);
    isConnecting = false;
    
  } catch (error) {
    console.error('âŒ MongoDB Connection Failed:', error.message);
    isConnecting = false;
    
    console.log('ðŸ”„ Retrying in 5 seconds...');
    setTimeout(connectDB, 5000);
  }
};

// Connection event handlers
mongoose.connection.on('disconnected', () => {
  console.log('âš ï¸ MongoDB disconnected. Attempting to reconnect...');
  connectDB();
});

mongoose.connection.on('error', (err) => {
  console.error('âŒ MongoDB error:', err);
});

// Start connection
connectDB();

// MongoDB Schemas (same as before)
const userSchema = new mongoose.Schema({
  firebaseUid: { type: String, required: true, unique: true, index: true },
  email: { type: String, required: true, unique: true },
  displayName: { type: String, required: true },
  companyName: { type: String, default: 'My Company' },
  photoURL: String,
  plan: { type: String, enum: ['free', 'pro', 'enterprise'], default: 'free' },
  createdAt: { type: Date, default: Date.now },
  lastLogin: { type: Date, default: Date.now }
});

const datasetSchema = new mongoose.Schema({
  userId: { type: String, required: true, index: true },
  datasetName: { type: String, required: true },
  rawData: { type: String, required: true },
  parsedData: {
    headers: [String],
    data: [[mongoose.Schema.Types.Mixed]]
  },
  metadata: {
    rowCount: Number,
    totalRevenue: Number,
    dateRange: String,
    industryType: String,
    dataQuality: { type: String, enum: ['excellent', 'good', 'fair', 'poor'], default: 'good' }
  },
  uploadedAt: { type: Date, default: Date.now }
});

const analysisSchema = new mongoose.Schema({
  userId: { type: String, required: true, index: true },
  userEmail: String,
  userName: String,
  datasetId: { type: mongoose.Schema.Types.ObjectId, ref: 'Dataset' },
  rawData: String,
  csvData: {
    headers: [String],
    data: [[mongoose.Schema.Types.Mixed]],
    fileName: String 
  },
  sqlQueries: [String],  
  analysis: {
    summary: String,
    metrics: {
      totalRevenue: Number,
      avgRevenue: Number,
      maxRevenue: Number,
      minRevenue: Number,
      totalQuantity: Number,
      growthRate: Number,
      dataPoints: Number
    }
  },
  questions: [{
    question: { type: String, required: true },
    answer: { type: String, required: true },
    confidence: { type: String, enum: ['high', 'medium', 'low'], default: 'medium' },
    timestamp: { type: Date, default: Date.now }
  }],
  industryType: String,
  tags: [String],
  timestamp: { type: Date, default: Date.now }
}, { timestamps: true });

analysisSchema.index({ userId: 1, timestamp: -1 });

const User = mongoose.model('User', userSchema);
const Dataset = mongoose.model('Dataset', datasetSchema);
const Analysis = mongoose.model('Analysis', analysisSchema);
// ============================================
// MONGODB MIDDLEWARE - Protect routes when DB is down
// ============================================
const requireMongoDB = (req, res, next) => {
  if (mongoose.connection.readyState !== 1) {
    return res.status(503).json({ 
      success: false, 
      error: 'Database temporarily unavailable. Please try again.' 
    });
  }
  next();
};

// âœ… Initialize Firebase Admin with Base64 Support
let admin;
try {
  let serviceAccount;
  
  if (process.env.FIREBASE_SERVICE_ACCOUNT_JSON) {
    // Production: Read from base64 environment variable
    console.log('ðŸ”‘ Loading Firebase credentials from base64 environment variable...');
    const base64Json = process.env.FIREBASE_SERVICE_ACCOUNT_JSON;
    const jsonString = Buffer.from(base64Json, 'base64').toString('utf-8');
    serviceAccount = JSON.parse(jsonString);
    console.log('âœ… Firebase credentials decoded from base64');
  } else if (process.env.FIREBASE_SERVICE_ACCOUNT_PATH) {
    // Alternative: Read from file path
    console.log('ðŸ”‘ Loading Firebase credentials from file path...');
    serviceAccount = require(process.env.FIREBASE_SERVICE_ACCOUNT_PATH);
  } else {
    // Local development: Read from local file
    console.log('ðŸ”‘ Loading Firebase credentials from local file...');
    serviceAccount = require('./firebase-service-account.json');
  }

  admin = require('firebase-admin');
  
  if (!admin.apps.length) {
    admin.initializeApp({
      credential: admin.credential.cert(serviceAccount)
    });
  }
  
  console.log('âœ… Firebase Admin initialized successfully');
  console.log('âœ… Project ID:', serviceAccount.project_id);
  
} catch (error) {
  console.error('âŒ Firebase Admin initialization failed:', error.message);
  console.log('ðŸ”“ Running in NO-AUTH mode for testing');
}
const verifyToken = async (req, res, next) => {
  try {
    if (!admin) {
      req.user = { uid: 'test-user', email: 'test@example.com', name: 'Test User' };
      return next();
    }
    const authHeader = req.headers.authorization;
    if (!authHeader || !authHeader.startsWith('Bearer ')) {
      return res.status(401).json({ success: false, error: 'Unauthorized: No token' });
    }
    const token = authHeader.split('Bearer ')[1];
    const decodedToken = await admin.auth().verifyIdToken(token);
    req.user = {
      uid: decodedToken.uid,
      email: decodedToken.email,
      name: decodedToken.name || decodedToken.email.split('@')[0],
      picture: decodedToken.picture
    };
    next();
  } catch (error) {
    console.error('âŒ Token verification failed:', error.message);
    return res.status(401).json({ success: false, error: 'Unauthorized: Invalid token' });
  }
};

// ============================================
// INDUSTRY DETECTION LOGIC
// ============================================
function detectIndustry(headers) {
  const headerStr = headers.join(',').toLowerCase();
  
  if (headerStr.includes('mau') || headerStr.includes('dau') || headerStr.includes('arpu') || headerStr.includes('retention')) {
    return 'fintech';
  }
  if (headerStr.includes('conversion') || headerStr.includes('ctr') || headerStr.includes('impressions') || headerStr.includes('clicks')) {
    return 'marketing';
  }
  if (headerStr.includes('product') || headerStr.includes('units') || headerStr.includes('inventory')) {
    return 'ecommerce';
  }
  if (headerStr.includes('subscription') || headerStr.includes('churn') || headerStr.includes('mrr')) {
    return 'saas';
  }
  return 'business'; // Generic business analytics
}

// ============================================
// ENHANCED DATA VALIDATION
// ============================================
function validateData(csvData) {
  const warnings = [];
  const rowCount = csvData.data.length;
  
  if (rowCount < 3) {
    warnings.push('âš ï¸ Very limited data. Analysis confidence: LOW');
  } else if (rowCount < 10) {
    warnings.push('âš ï¸ Small dataset. Consider adding more data');
  }
  
  // Detect revenue/amount column
  const revenueColIndex = csvData.headers.findIndex(h => 
    h.toLowerCase().includes('revenue') || 
    h.toLowerCase().includes('amount') ||
    h.toLowerCase().includes('sales')
  );
  
  let totalRevenue = 0;
  if (revenueColIndex !== -1) {
    const hasNegative = csvData.data.some(row => row[revenueColIndex] < 0);
    if (hasNegative) {
      warnings.push('âŒ Negative values detected. Please verify data');
    }
    
    totalRevenue = csvData.data.reduce((sum, row) => {
      const value = parseFloat(row[revenueColIndex]) || 0;
      return sum + value;
    }, 0);
  }
  
  let confidence = rowCount >= 50 ? 'high' : rowCount >= 10 ? 'medium' : 'low';
  
  return { 
    warnings, 
    totalRevenue, 
    confidence, 
    rowCount,
    industryType: detectIndustry(csvData.headers)
  };
}

// ============================================
// GROQ API HELPER WITH DETAILED LOGGING
// ============================================
async function callGroqAPI(messages) {
  // âœ… SECURE: Conditional logging only in development
  if (process.env.NODE_ENV === 'development') {
    console.log('ðŸ¤– [GROQ] Starting API call...');
    console.log('ðŸ¤– [GROQ] API Key present:', !!GROQ_API_KEY);
  }
  
  if (!GROQ_API_KEY) {
    console.error('âŒ [GROQ] API Key is missing!');
    throw new Error('GROQ_API_KEY is not configured');
  }

  if (!GROQ_API_KEY.startsWith('gsk_')) {
    console.error('âŒ [GROQ] Invalid API Key format!');
    // âœ… SECURE: No key details in production
    if (process.env.NODE_ENV === 'development') {
      console.error('   Expected: gsk_...');
      console.error('   Got:', GROQ_API_KEY.substring(0, 10) + '...');
    }
    throw new Error('Invalid GROQ_API_KEY format. Key should start with "gsk_"');
  }
  const requestPayload = {
    model: 'llama-3.3-70b-versatile',
    messages: messages,
    temperature: 0.7,
    max_tokens: 4000
  };

  console.log('ðŸ¤– [GROQ] Request payload:', JSON.stringify({
    model: requestPayload.model,
    messageCount: messages.length,
    temperature: requestPayload.temperature,
    max_tokens: requestPayload.max_tokens
  }));

  try {
    console.log('ðŸ¤– [GROQ] Sending request to:', GROQ_API_URL);
    
    const response = await axios.post(GROQ_API_URL, requestPayload, {
      headers: {
        'Authorization': `Bearer ${GROQ_API_KEY}`,
        'Content-Type': 'application/json'
      },
      timeout: 30000
    });
    
    console.log('âœ… [GROQ] API call successful!');
    console.log('âœ… [GROQ] Response status:', response.status);
    console.log('âœ… [GROQ] Response length:', response.data.choices[0].message.content.length);
    
    return response.data.choices[0].message.content;
    
  } catch (error) {
    console.error('âŒ [GROQ] API call failed!');
    
    if (error.response) {
      console.error('âŒ [GROQ] Status:', error.response.status);
      console.error('âŒ [GROQ] Error data:', JSON.stringify(error.response.data, null, 2));
      console.error('âŒ [GROQ] Headers:', JSON.stringify(error.response.headers, null, 2));
      
      const errorMessage = error.response.data?.error?.message || 'Unknown error';
      throw new Error(`GROQ API Error (${error.response.status}): ${errorMessage}`);
      
    } else if (error.request) {
      console.error('âŒ [GROQ] Network error - no response received');
      throw new Error('Network error connecting to GROQ API');
      
    } else {
      console.error('âŒ [GROQ] Unexpected error:', error.message);
      console.error('âŒ [GROQ] Stack trace:', error.stack);
      throw error;
    }
  }
}

// ============================================
// COMPREHENSIVE STATISTICAL AGGREGATION
// ============================================
const calculateComprehensiveStats = (csvData) => {
  const { headers, data } = csvData;
  
  if (!data || data.length === 0) {
    return null;
  }

  const stats = {
    overview: {
      totalRows: data.length,
      dataQuality: data.length >= 1000 ? 'excellent' : data.length >= 100 ? 'good' : 'fair',
      timeRange: 'full dataset'
    },
    columns: {},
    patterns: {},
    segments: {}
  };

  // Analyze each column
  headers.forEach((header, colIndex) => {
    const values = data.map(row => row[colIndex]);
    const columnType = typeof values[0] === 'number' ? 'numeric' : 'categorical';
    
    if (columnType === 'numeric') {
      // Numeric column analysis
      const numericValues = values.filter(v => typeof v === 'number' && !isNaN(v));
      
      if (numericValues.length > 0) {
        const sorted = [...numericValues].sort((a, b) => a - b);
        const sum = numericValues.reduce((a, b) => a + b, 0);
        
        stats.columns[header] = {
          type: 'numeric',
          count: numericValues.length,
          sum: sum,
          mean: sum / numericValues.length,
          median: sorted[Math.floor(sorted.length / 2)],
          min: sorted[0],
          max: sorted[sorted.length - 1],
          stdDev: calculateStdDev(numericValues),
          distribution: createDistribution(numericValues, 5)
        };
      }
    } else {
      // Categorical column analysis
      const frequency = {};
      values.forEach(val => {
        const key = String(val);
        frequency[key] = (frequency[key] || 0) + 1;
      });
      
      const sorted = Object.entries(frequency)
        .sort((a, b) => b[1] - a[1])
        .slice(0, 10);
      
      stats.columns[header] = {
        type: 'categorical',
        uniqueValues: Object.keys(frequency).length,
        topValues: sorted.map(([value, count]) => ({
          value,
          count,
          percentage: ((count / data.length) * 100).toFixed(2)
        })),
        distribution: Object.fromEntries(sorted)
      };
    }
  });

  // Detect revenue/amount columns
  const revenueCol = headers.findIndex(h => 
    h.toLowerCase().includes('revenue') || 
    h.toLowerCase().includes('amount') || 
    h.toLowerCase().includes('sales') ||
    h.toLowerCase().includes('price')
  );

  if (revenueCol >= 0 && stats.columns[headers[revenueCol]]) {
    const revenueStats = stats.columns[headers[revenueCol]];
    stats.overview.totalRevenue = revenueStats.sum;
    stats.overview.avgRevenue = revenueStats.mean;
    stats.overview.revenueRange = `â‚¹${revenueStats.min.toLocaleString()} - â‚¹${revenueStats.max.toLocaleString()}`;
  }

  // Detect quantity columns
  const quantityCol = headers.findIndex(h => 
    h.toLowerCase().includes('quantity') || 
    h.toLowerCase().includes('units') || 
    h.toLowerCase().includes('count')
  );

  if (quantityCol >= 0 && stats.columns[headers[quantityCol]]) {
    stats.overview.totalQuantity = stats.columns[headers[quantityCol]].sum;
  }

  // Time-based analysis (if date column exists)
  const dateCol = headers.findIndex(h => 
    h.toLowerCase().includes('date') || 
    h.toLowerCase().includes('month') || 
    h.toLowerCase().includes('year') ||
    h.toLowerCase().includes('time')
  );

  if (dateCol >= 0) {
    const timeValues = data.map(row => row[dateCol]);
    const timeDistribution = {};
    
    timeValues.forEach(val => {
      const key = String(val);
      timeDistribution[key] = (timeDistribution[key] || 0) + 1;
    });
    
    stats.patterns.timeSeriesDistribution = Object.entries(timeDistribution)
      .sort((a, b) => a[0].localeCompare(b[0]))
      .map(([period, count]) => ({ period, count }));
    
    // Calculate growth if we have revenue
    if (revenueCol >= 0) {
      const periods = Object.keys(timeDistribution).sort();
      if (periods.length >= 2) {
        const firstPeriod = periods[0];
        const lastPeriod = periods[periods.length - 1];
        
        const firstPeriodData = data.filter(row => String(row[dateCol]) === firstPeriod);
        const lastPeriodData = data.filter(row => String(row[dateCol]) === lastPeriod);
        
        const firstRevenue = firstPeriodData.reduce((sum, row) => sum + (row[revenueCol] || 0), 0);
        const lastRevenue = lastPeriodData.reduce((sum, row) => sum + (row[revenueCol] || 0), 0);
        
        if (firstRevenue > 0) {
          stats.overview.growthRate = ((lastRevenue - firstRevenue) / firstRevenue) * 100;
        }
      }
    }
  } else {
    // NO DATE COLUMN - Set growth rate to null explicitly
    stats.overview.growthRate = null;
    stats.overview.growthRateDisabled = true;
    stats.overview.growthRateReason = 'No date/time column found';
  }

  // Status/Category segmentation
  const statusCol = headers.findIndex(h => 
    h.toLowerCase().includes('status') || 
    h.toLowerCase().includes('state') ||
    h.toLowerCase().includes('category')
  );

  if (statusCol >= 0) {
    const statusValues = data.map(row => row[statusCol]);
    const statusFreq = {};
    
    statusValues.forEach(val => {
      const key = String(val);
      statusFreq[key] = (statusFreq[key] || 0) + 1;
    });
    
    stats.segments.byStatus = Object.entries(statusFreq).map(([status, count]) => ({
      status,
      count,
      percentage: ((count / data.length) * 100).toFixed(2)
    }));

    // Churn analysis if status contains "churn"
    const churnedCount = statusValues.filter(v => 
      String(v).toLowerCase().includes('churn')
    ).length;
    
    if (churnedCount > 0) {
      stats.overview.churnRate = ((churnedCount / data.length) * 100).toFixed(2);
      stats.overview.churnedUsers = churnedCount;
      stats.overview.activeUsers = data.length - churnedCount;
    }
  }

  // Geographic analysis
  const countryCol = headers.findIndex(h => 
    h.toLowerCase().includes('country') || 
    h.toLowerCase().includes('region') ||
    h.toLowerCase().includes('location')
  );

  if (countryCol >= 0) {
    const countries = data.map(row => row[countryCol]);
    const countryFreq = {};
    
    countries.forEach(val => {
      const key = String(val);
      countryFreq[key] = (countryFreq[key] || 0) + 1;
    });
    
    stats.segments.byGeography = Object.entries(countryFreq)
      .sort((a, b) => b[1] - a[1])
      .slice(0, 10)
      .map(([country, count]) => ({
        country,
        count,
        percentage: ((count / data.length) * 100).toFixed(2)
      }));
  }

  // Channel analysis
  const channelCol = headers.findIndex(h => 
    h.toLowerCase().includes('channel') || 
    h.toLowerCase().includes('source') ||
    h.toLowerCase().includes('acquisition')
  );

  if (channelCol >= 0) {
    const channels = data.map(row => row[channelCol]);
    const channelFreq = {};
    
    channels.forEach(val => {
      const key = String(val);
      channelFreq[key] = (channelFreq[key] || 0) + 1;
    });
    
    stats.segments.byChannel = Object.entries(channelFreq)
      .sort((a, b) => b[1] - a[1])
      .map(([channel, count]) => ({
        channel,
        count,
        percentage: ((count / data.length) * 100).toFixed(2)
      }));
  }

  return stats;
};

// Helper function: Calculate standard deviation
const calculateStdDev = (values) => {
  const mean = values.reduce((a, b) => a + b, 0) / values.length;
  const squareDiffs = values.map(value => Math.pow(value - mean, 2));
  const avgSquareDiff = squareDiffs.reduce((a, b) => a + b, 0) / values.length;
  return Math.sqrt(avgSquareDiff);
};

// Helper function: Create distribution buckets
const createDistribution = (values, bucketCount = 5) => {
  const sorted = [...values].sort((a, b) => a - b);
  const min = sorted[0];
  const max = sorted[sorted.length - 1];
  const bucketSize = (max - min) / bucketCount;
  
  const buckets = {};
  for (let i = 0; i < bucketCount; i++) {
    const start = min + (i * bucketSize);
    const end = i === bucketCount - 1 ? max : start + bucketSize;
    const key = `${start.toFixed(0)}-${end.toFixed(0)}`;
    buckets[key] = 0;
  }
  
  values.forEach(val => {
    const bucketIndex = Math.min(Math.floor((val - min) / bucketSize), bucketCount - 1);
    const start = min + (bucketIndex * bucketSize);
    const end = bucketIndex === bucketCount - 1 ? max : start + bucketSize;
    const key = `${start.toFixed(0)}-${end.toFixed(0)}`;
    buckets[key]++;
  });
  
  return buckets;
};

// ============================================
// TEXT-TO-SPEECH FORMATTING HELPER
// ============================================
const convertToIndianFormat = (text) => {
  // Convert large numbers to lakhs/crores for better speech
  return text.replace(/â‚¹[\d,]+/g, (match) => {
    const number = parseFloat(match.replace(/[â‚¹,]/g, ''));
    
    if (isNaN(number)) return match;
    
    if (number >= 10000000) {
      // Crores
      const crores = number / 10000000;
      // âœ… FIXED: Remove "rupees" when using lakhs/crores
      return crores % 1 === 0 
        ? `${crores} crore` 
        : `${crores.toFixed(2)} crore`;
    } else if (number >= 100000) {
      // Lakhs
      const lakhs = number / 100000;
      // âœ… FIXED: Remove "rupees" when using lakhs/crores
      return lakhs % 1 === 0 
        ? `${lakhs} lakh` 
        : `${lakhs.toFixed(2)} lakh`;
    } else if (number >= 1000) {
      // Thousands - add "rupees" for smaller amounts
      return `${number.toLocaleString('en-IN')} rupees`;
    } else {
      return `${number} rupees`;
    }
  });
};

// ============================================
// SMART SAMPLING FOR EXAMPLES
// ============================================
const extractRepresentativeSamples = (csvData, sampleSize = 60) => {
  const { headers, data } = csvData;
  
  if (data.length <= sampleSize) {
    return { headers, data };
  }

  const samples = [];
  
  // Strategy 1: First rows (early period)
  samples.push(...data.slice(0, Math.min(15, data.length)));
  
  // Strategy 2: Last rows (recent period)
  samples.push(...data.slice(-15));
  
  // Strategy 3: High performers (if revenue column exists)
  const revenueCol = headers.findIndex(h => 
    h.toLowerCase().includes('revenue') || 
    h.toLowerCase().includes('amount')
  );
  
  if (revenueCol >= 0) {
    const sorted = [...data].sort((a, b) => (b[revenueCol] || 0) - (a[revenueCol] || 0));
    samples.push(...sorted.slice(0, 10));
  }
  
  // Strategy 4: Churned/Problem cases (if status column exists)
  const statusCol = headers.findIndex(h => 
    h.toLowerCase().includes('status')
  );
  
  if (statusCol >= 0) {
    const churned = data.filter(row => 
      String(row[statusCol]).toLowerCase().includes('churn')
    );
    samples.push(...churned.slice(0, 10));
  }
  
  // Strategy 5: Random diverse samples
  const step = Math.floor(data.length / 10);
  for (let i = 0; i < data.length && samples.length < sampleSize; i += step) {
    samples.push(data[i]);
  }
  
  // Remove duplicates
  const uniqueSamples = Array.from(
    new Set(samples.map(row => JSON.stringify(row)))
  ).map(str => JSON.parse(str));
  
  return {
    headers,
    data: uniqueSamples.slice(0, sampleSize)
  };
};

// ============================================
// DEMO DATASETS API
// ============================================
app.get('/api/demo-datasets', (req, res) => {
  const datasets = {
    ecommerce: {
      name: "E-commerce Sales Demo",
      data: `Month,Product,Units,Revenue
January,Mobile,850,680000
January,Laptop,320,1440000
February,Mobile,920,736000
February,Laptop,340,1530000
March,Mobile,980,784000
March,Laptop,365,1642500
April,Mobile,1050,840000
April,Laptop,380,1710000`
    },
    fintech: {
      name: "FinTech Metrics Demo",
      data: `Month,MAU,Paying_Users,Transactions,Revenue,ARPU,Retention
July,125000,48000,890000,625000,5.00,78.5
August,132000,52000,945000,660000,5.00,79.2
September,138000,55000,985000,690000,5.00,80.1
October,145000,58000,1050000,725000,5.00,81.0
November,142000,56000,1020000,710000,5.00,79.8
December,148000,60000,1100000,740000,5.00,82.0`
    },
    marketing: {
      name: "Marketing Campaign Demo",
      data: `Campaign,Impressions,Clicks,Conversions,Spend,Revenue
Google_Ads,50000,2500,150,25000,90000
Facebook,45000,2200,120,20000,72000
Instagram,38000,1900,100,18000,60000
LinkedIn,28000,1400,80,15000,48000
Twitter,35000,1750,95,17000,57000`
    }
  };
  
  res.json({ success: true, datasets });
});

// ============================================
// FILE UPLOAD ENDPOINT
// ============================================

// Configure multer for file uploads
const upload = multer({ 
  dest: 'uploads/',
  limits: { fileSize: 50 * 1024 * 1024 } // 50MB limit
});

// File upload endpoint
// âœ… SECURE: Protected file upload with validation
app.post('/api/upload-file', verifyToken, uploadLimiter, upload.single('file'), async (req, res) => {
  let filePath = null;
  
  try {
    if (!req.file) {
      return res.status(400).json({ success: false, error: 'No file uploaded' });
    }

    const file = req.file;
    filePath = file.path;

    console.log(`ðŸ“ Processing file: ${file.originalname} (${(file.size / 1024).toFixed(2)} KB)`);
    console.log(`ðŸ‘¤ User: ${req.user.email}`);

    // âœ… SECURITY: Validate file extension
    const allowedExtensions = ['csv', 'xlsx', 'xls', 'pdf', 'docx', 'doc'];
    const fileExtension = file.originalname.split('.').pop().toLowerCase();
    
    if (!allowedExtensions.includes(fileExtension)) {
      fs.unlinkSync(filePath);
      return res.status(400).json({ 
        success: false, 
        error: 'Invalid file type. Only CSV, Excel, PDF, and Word files are allowed.' 
      });
    }

    // âœ… SECURITY: Validate MIME type (prevent extension spoofing)
    const allowedMimeTypes = [
      'text/csv', 
      'text/plain',
      'application/vnd.ms-excel',
      'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
      'application/pdf',
      'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
      'application/msword'
    ];
    
    const isValidType = await validateFileType(filePath, allowedMimeTypes);
    if (!isValidType && fileExtension !== 'csv') {
      fs.unlinkSync(filePath);
      return res.status(400).json({ 
        success: false, 
        error: 'File content does not match its extension. Potential security risk detected.' 
      });
    }

    // âœ… SECURITY: Validate file size (already limited by multer, but double-check)
    const maxSize = 50 * 1024 * 1024; // 50MB
    if (file.size > maxSize) {
      fs.unlinkSync(filePath);
      return res.status(400).json({ 
        success: false, 
        error: 'File too large. Maximum size is 50MB.' 
      });
    }

    let extractedData = '';

    // Process CSV files
    if (fileExtension === 'csv') {
      const rawData = fs.readFileSync(file.path, 'utf-8');
      
      // âœ… SECURITY: Sanitize CSV content to prevent formula injection
      extractedData = sanitizeCSV(rawData);
      
      const lineCount = extractedData.split('\n').length;
      console.log(`ðŸ“Š CSV has ${lineCount} lines`);
      
      if (lineCount > 10000) {
        console.warn(`âš ï¸ Very large CSV (${lineCount} lines) - may take longer to process`);
      }
    }
    
    // Process Excel files
    else if (fileExtension === 'xlsx' || fileExtension === 'xls') {
      const workbook = XLSX.readFile(file.path);
      const sheetName = workbook.SheetNames[0];
      const sheet = workbook.Sheets[sheetName];
      const rawCSV = XLSX.utils.sheet_to_csv(sheet);
      
      // âœ… SECURITY: Sanitize Excel-generated CSV
      extractedData = sanitizeCSV(rawCSV);
      
      const lineCount = extractedData.split('\n').length;
      console.log(`ðŸ“Š Excel converted to CSV with ${lineCount} lines`);
    }
    
    // Process PDF files
    else if (fileExtension === 'pdf') {
      const dataBuffer = fs.readFileSync(file.path);
      const pdfData = await pdf(dataBuffer);
      extractedData = pdfData.text;
      console.log(`ðŸ“„ PDF extracted: ${pdfData.numpages} pages`);
    }
    
    // Process Word files
    else if (fileExtension === 'docx' || fileExtension === 'doc') {
      const result = await mammoth.extractRawText({ path: file.path });
      extractedData = result.value;
      console.log(`ðŸ“ Word document extracted`);
    }

    // âœ… SECURITY: Validate extracted data
    if (!extractedData || extractedData.trim().length === 0) {
      return res.status(400).json({ 
        success: false, 
        error: 'Could not extract data from file. File may be corrupted or empty.' 
      });
    }

    // âœ… SECURITY: Limit extracted data size
    const maxExtractedSize = 10 * 1024 * 1024; // 10MB text
    if (extractedData.length > maxExtractedSize) {
      extractedData = extractedData.substring(0, maxExtractedSize);
      console.warn('âš ï¸ Data truncated to 10MB');
    }

    const dataSizeKB = Buffer.byteLength(extractedData, 'utf8') / 1024;
    console.log(`ðŸ“¦ Extracted data size: ${dataSizeKB.toFixed(2)} KB`);

    res.json({
      success: true,
      extractedData: extractedData,
      fileName: sanitizeFilename(file.originalname),
      fileSize: file.size,
      extractedSize: dataSizeKB,
      rowCount: extractedData.split('\n').length
    });

  } catch (error) {
    console.error('âŒ File processing error:', error.message);
    handleError(res, error, 'Failed to process file. Please ensure the file is not corrupted.');
  } finally {
    // âœ… SECURITY: Always cleanup uploaded file
    if (filePath && fs.existsSync(filePath)) {
      try {
        fs.unlinkSync(filePath);
        console.log('ðŸ—‘ï¸ Cleaned up file:', filePath);
      } catch (cleanupError) {
        console.error('âš ï¸ File cleanup failed:', cleanupError.message);
      }
    }
  }
});
// ============================================
// ROUTES
// ============================================

app.get('/api/health', (req, res) => {
  const health = {
    status: 'OK',
    timestamp: new Date().toISOString(),
    uptime: process.uptime(),
    environment: process.env.NODE_ENV || 'development',
    checks: {
      mongodb: mongoose.connection.readyState === 1 ? 'connected' : 'disconnected',
      groq: GROQ_API_KEY ? 'configured' : 'missing',
      firebase: admin ? 'configured' : 'missing'
    },
    version: '1.0.0'
  };
  
  const isHealthy = 
    health.checks.mongodb === 'connected' && 
    health.checks.groq === 'configured';
  
  const statusCode = isHealthy ? 200 : 503;
  
  if (!isHealthy) {
    health.status = 'DEGRADED';
  }
  
  res.status(statusCode).json(health);
});
app.post('/api/auth/login', verifyToken, async (req, res) => {
  try {
    const { uid, email, name, picture } = req.user;
    let user = await User.findOne({ firebaseUid: uid });
    if (!user) {
      user = await User.create({
        firebaseUid: uid,
        email: email,
        displayName: name,
        photoURL: picture
      });
      console.log('âœ… New user created:', email);
    } else {
      user.lastLogin = new Date();
      await user.save();
    }
    res.json({ success: true, user });
  } catch (error) {
    handleError(res, error, 'Failed to login. Please try again.');
  }
});

app.post('/api/parse-data', verifyToken, async (req, res) => {
  console.log('ðŸ“¥ [PARSE] ==================== NEW PARSE REQUEST ====================');
  
  try {
    const { rawData } = req.body;
    
    console.log('ðŸ“¥ [PARSE] User:', req.user.email);
    console.log('ðŸ“¥ [PARSE] Raw data length:', rawData?.length || 0);
    
    if (!rawData?.trim()) {
      console.error('âŒ [PARSE] No data provided');
      return res.status(400).json({ success: false, error: 'No data provided' });
    }

    // Sanitize and limit input size
    const sanitizedData = rawData
      .replace(/<script\b[^<]*(?:(?!<\/script>)<[^<]*)*<\/script>/gi, '')
      .replace(/<iframe\b[^<]*(?:(?!<\/iframe>)<[^<]*)*<\/iframe>/gi, '')
      .slice(0, 5000000); // 5MB text limit

    console.log('ðŸ“Š Parsing data for user:', req.user.email);
    
    const lines = sanitizedData.trim().split('\n');
    const firstLine = lines[0];
    const rowCount = lines.length;
    
    // Check if already CSV format
    const isAlreadyCSV = firstLine.includes(',') && rowCount > 1;
    
    let csvText;
    let processingMethod = '';
    
    // ============================================
    // TIER 1: SMALL FILES (â‰¤50 rows) - AI Enhanced
    // ============================================
    if (isAlreadyCSV && rowCount <= 50) {
      console.log('ðŸ¤– Small CSV detected (', rowCount, 'rows) - using AI for cleanup');
      processingMethod = 'ai_enhanced';
      
      const prompt = `Clean and standardize this CSV. Return ONLY the CSV, no explanations.

DATA: ${sanitizedData}

RULES:
- Keep all columns
- Standardize formatting
- Remove any invalid rows
- NO markdown, NO explanations

CSV:`;

      csvText = await callGroqAPI([
        { role: 'system', content: 'Return ONLY CSV format, no explanations.' },
        { role: 'user', content: prompt }
      ]);
      
    } 
    // ============================================
    // TIER 2: MEDIUM FILES (51-1000 rows) - Direct Parse
    // ============================================
    else if (isAlreadyCSV && rowCount > 50 && rowCount <= 1000) {
      console.log('âœ… Medium CSV detected (', rowCount, 'rows) - parsing directly');
      processingMethod = 'direct_parse';
      csvText = sanitizedData.trim();
      
    } 
    // ============================================
    // TIER 3: LARGE FILES (1000+ rows) - Smart Sampling
    // ============================================
    else if (isAlreadyCSV && rowCount > 1000) {
      console.log('ðŸ“¦ Large CSV detected (', rowCount, 'rows) - using smart sampling');
      processingMethod = 'smart_sampling';
      
      // Process the full dataset directly (no AI needed for valid CSV)
      csvText = sanitizedData.trim();
      
    } 
    // ============================================
    // TIER 4: UNSTRUCTURED DATA - AI Conversion
    // ============================================
    else {
      console.log('ðŸ¤– Unstructured data detected - using AI to convert');
      processingMethod = 'ai_conversion';
      
      // For large unstructured data, send only first 200 lines
      const sampleData = rowCount > 200 
        ? lines.slice(0, 200).join('\n') + '\n\n... (Dataset continues with ' + (rowCount - 200) + ' more rows)'
        : sanitizedData;
      
      const prompt = `Parse this data into CSV format. Return ONLY the CSV, no explanations.

DATA: ${sampleData}

RULES:
- Extract all columns (dates, products, quantities, amounts, metrics, etc.)
- First row: headers
- Clean and standardize
- NO markdown, NO explanations

CSV:`;

      try {
        csvText = await callGroqAPI([
          { role: 'system', content: 'Return ONLY CSV format, no explanations.' },
          { role: 'user', content: prompt }
        ]);
      } catch (apiError) {
        if (apiError.response?.status === 413) {
          console.error('âš ï¸ Payload too large for AI - falling back to direct parse');
          csvText = sanitizedData.trim();
          processingMethod = 'fallback_direct';
        } else {
          throw apiError;
        }
      }
    }

    // ============================================
    // PARSE CSV INTO STRUCTURED FORMAT
    // ============================================
    let cleanedCSV = csvText.trim()
      .replace(/```csv\n?/g, '')
      .replace(/```/g, '')
      .replace(/\r\n/g, '\n');
    
    const csvLines = cleanedCSV.split('\n').filter(line => line.trim() && !line.includes('... ('));
    
    if (csvLines.length < 2) {
      return res.status(400).json({ 
        success: false, 
        error: 'Could not parse data. Please ensure file has at least a header row and one data row.' 
      });
    }
    
    // Parse headers
    const headers = csvLines[0].split(',').map(h => h.trim().replace(/"/g, ''));
    
    // Parse data rows with error handling
    const data = [];
    let skippedRows = 0;
    
    for (let i = 1; i < csvLines.length; i++) {
      try {
        const row = csvLines[i].split(',').map(cell => {
          const cleaned = cell.trim().replace(/"/g, '');
          const num = parseFloat(cleaned.replace(/[$,â‚¹]/g, ''));
          return isNaN(num) ? cleaned : num;
        });
        
        // Only add rows with correct column count
        if (row.length === headers.length) {
          data.push(row);
        } else {
          skippedRows++;
        }
      } catch (rowError) {
        skippedRows++;
        console.warn(`âš ï¸ Skipped malformed row ${i}`);
      }
    }

    if (data.length === 0) {
      return res.status(400).json({ 
        success: false, 
        error: 'No valid data rows found after parsing.' 
      });
    }

    console.log(`âœ… Parsed ${data.length} valid rows (skipped ${skippedRows} malformed rows)`);

    const csvData = { headers, data };
    const validation = validateData(csvData);
    
    console.log('ðŸ­ DETECTED INDUSTRY:', validation.industryType);
    console.log('ðŸ“Š Data Quality:', validation.confidence);
    console.log('ðŸ“ˆ Total Revenue:', validation.totalRevenue);
    console.log('ðŸ”§ Processing Method:', processingMethod);
    
    // Save to database with size-aware storage
    const shouldStoreFullData = data.length <= 1000;
    
    const dataset = await Dataset.create({
      userId: req.user.uid,
      datasetName: `Dataset ${new Date().toLocaleDateString()}`,
      rawData: shouldStoreFullData ? rawData.substring(0, 50000) : rawData.substring(0, 10000),
      parsedData: shouldStoreFullData ? csvData : {
        headers: csvData.headers,
        data: csvData.data.slice(0, 1000)
      },
      metadata: {
        rowCount: validation.rowCount,
        totalRevenue: validation.totalRevenue,
        industryType: validation.industryType,
        dataQuality: validation.confidence === 'high' ? 'excellent' : 
                     validation.confidence === 'medium' ? 'good' : 'fair',
        processingMethod: processingMethod,
        originalRowCount: rowCount,
        skippedRows: skippedRows
      }
    });

    console.log(`âœ… Dataset saved with ID: ${dataset._id}`);
    
    res.json({ 
      success: true, 
      csvData, 
      rowCount: data.length,
      originalRowCount: rowCount,
      skippedRows: skippedRows,
      validation,
      datasetId: dataset._id,
      industryType: validation.industryType,
      processingMethod: processingMethod,
      message: data.length >= 1000 
        ? `Successfully processed large dataset with ${data.length.toLocaleString()} rows!` 
        : null
    });
    
  } catch (error) {
    console.error('âŒ Parse error:', error);
    
    let errorMessage = 'Failed to parse data. ';
    
    if (error.response?.status === 413) {
      errorMessage += 'File is too large for AI processing. Please ensure your CSV is properly formatted.';
    } else if (error.message.includes('timeout')) {
      errorMessage += 'Processing took too long. Please try with a smaller file or check your connection.';
    } else {
      errorMessage += error.message;
    }
    
    res.status(500).json({ success: false, error: errorMessage });
  }
});

// ============================================
// COMPLETE FIXED /api/analyze ENDPOINT
// Replace your existing endpoint with this
// ============================================

app.post('/api/analyze', verifyToken, async (req, res) => {
  console.log('📊 [ANALYZE] ==================== NEW ANALYSIS REQUEST ====================');

  try {
    const { question, csvData, datasetId } = req.body;

    console.log('📊 [ANALYZE] User:', req.user.email);
    console.log('📊 [ANALYZE] Question:', question?.substring(0, 100) + '...');
    console.log('📊 [ANALYZE] CSV Data present:', !!csvData);
    console.log('📊 [ANALYZE] Dataset ID:', datasetId || 'none');

    if (!question || !csvData) {
      console.error('❌ [ANALYZE] Missing required data');
      return res.status(400).json({ success: false, error: 'Missing data' });
    }

    const rowCount = csvData.data.length;

    // ============================================
    // 🚨 PRODUCTION VALIDATION - CRITICAL
    // ============================================
    console.log('🔍 Running production validation...');

    const dataValidation = validateDataIntegrity(csvData);

    if (!dataValidation.valid) {
      console.error('❌ Data validation failed:', dataValidation.errors);
      return res.status(400).json({
        success: false,
        error: 'Data validation failed: ' + dataValidation.errors.join(', '),
        details: dataValidation.errors
      });
    }

    // Check metric eligibility
    const growthCheck = canCalculateGrowth(csvData);
    const statsCheck = canPerformStatistics(csvData);
    const forecastCheck = canForecast(csvData);

    console.log('✅ Validated Totals:', {
      revenue: dataValidation.validated.totalRevenue,
      spend: dataValidation.validated.totalSpend,
      rows: dataValidation.validated.rowCount
    });

    console.log('📊 Metric Eligibility:', {
      growth: growthCheck.allowed,
      statistics: statsCheck.allowed,
      forecasting: forecastCheck.allowed
    });

    // Store validated totals for AI prompt
    const VALIDATED_TOTALS = {
      totalRevenue: dataValidation.validated.totalRevenue,
      avgRevenue: dataValidation.validated.avgRevenue,
      totalSpend: dataValidation.validated.totalSpend,
      rowCount: dataValidation.validated.rowCount
    };

    // ============================================
    // Calculate Schema-Aware Industry Metrics
    // ============================================
    const availableColumns = detectAvailableMetrics(csvData.headers);
    const industryType = detectIndustryType(availableColumns);
    const schemaMetrics = generateIndustryMetrics(csvData, industryType, availableColumns);

    console.log('🎯 Detected Industry:', industryType);
    console.log('📊 Schema-Aware Metrics:', schemaMetrics);

    // Generate column mapping to prevent "undefined" in SQL
    const columnMap = mapColumnNames(csvData);
    console.log('🗺️ Column Mapping:', columnMap);

    // Generate SQL with validated column names
    const sqlQueries = generateValidatedSQL(csvData, schemaMetrics, availableColumns);
    console.log('🗄️ SQL Queries Generated:', sqlQueries.length);

// ============================================
// ADVANCED STATISTICAL ANALYSIS ENGINE
// ============================================
let statisticalResults = null;

if (statsCheck.allowed) {
  console.log('📊 Sample size adequate - running ADVANCED statistical analysis...');

  // Find ALL numeric columns with sufficient data (10+ valid values)
  const numericColumns = csvData.headers
    .map((header, index) => {
      const values = csvData.data
        .map(row => parseFloat(row[index]))
        .filter(val => !isNaN(val) && isFinite(val));
      
      return values.length >= 10 ? { header, index, values } : null;
    })
    .filter(Boolean);

  if (numericColumns.length > 0) {
    // Prioritize revenue/sales columns, fallback to first numeric
    const primaryColumn = numericColumns.find(col => 
      col.header.toLowerCase().includes('revenue') ||
      col.header.toLowerCase().includes('sales') ||
      col.header.toLowerCase().includes('amount') ||
      col.header.toLowerCase().includes('price') ||
      col.header.toLowerCase().includes('value')
    ) || numericColumns[0];

    console.log(`📊 Analyzing column: ${primaryColumn.header} (${primaryColumn.values.length} values)`);

    // 🔥 USE THE ADVANCED STATISTICS ENGINE (100% accurate mathematics)
    const stats = new AdvancedStatistics(primaryColumn.values, primaryColumn.header);
    statisticalResults = stats.getFullAnalysis();

    console.log('✅ ADVANCED statistics computed:', {
      sampleSize: statisticalResults.sampleSize,
      mean: statisticalResults.mean?.toFixed(2),
      median: statisticalResults.median?.toFixed(2),
      stdDev: statisticalResults.standardDeviation?.toFixed(2),
      variance: statisticalResults.variance?.toFixed(2),
      outliers_IQR: statisticalResults.outliersIQR?.count || 0,
      outliers_ZScore: statisticalResults.outliersZScore?.count || 0,
      trend: statisticalResults.trendAnalysis?.trendDirection || 'N/A',
      rSquared: statisticalResults.trendAnalysis?.rSquared?.toFixed(4) || 'N/A',
      skewness: statisticalResults.skewness?.toFixed(4) || 'N/A',
      kurtosis: statisticalResults.kurtosis?.toFixed(4) || 'N/A'
    });
  } else {
    console.log('⚠️ No numeric columns with sufficient data (need 10+ valid values)');
    statisticalResults = {
      disabled: true,
      reason: 'No numeric columns found with 10+ valid data points',
      sampleSize: csvData.data.length
    };
  }
} else {
  console.log(`⚠️ Statistical analysis disabled: ${csvData?.data?.length || 0} rows (need 10+)`);
  statisticalResults = {
    disabled: true,
    reason: statsCheck.reason || `Sample size too small (${csvData?.data?.length || 0} rows, need 10+)`,
    sampleSize: csvData?.data?.length || 0
  };
}

    // ============================================
    // PREPARE DATA FOR AI
    // ============================================
    let dataContext = '';
    let sampleData = '';

    if (rowCount > 100) {
      console.log(`📊 Large dataset (${rowCount} rows) - using aggregation`);
      
      // Get first 10 and last 5 rows for context
      const firstRows = csvData.data.slice(0, 10);
      const lastRows = csvData.data.slice(-5);
      
      sampleData = `
📋 Sample Data (First 10 rows):
${csvData.headers.join(' | ')}
${firstRows.map(row => row.join(' | ')).join('\n')}

... (${rowCount - 15} more rows) ...

📋 Recent Data (Last 5 rows):
${lastRows.map(row => row.join(' | ')).join('\n')}
`;
    } else {
      // Show all data for small datasets
      sampleData = `
📋 Complete Dataset (${rowCount} rows):
${csvData.headers.join(' | ')}
${csvData.data.map(row => row.join(' | ')).join('\n')}
`;
    }

    dataContext = `
📊 COMPREHENSIVE DATASET ANALYSIS
Total Rows Analyzed: ${rowCount.toLocaleString()}
Industry Detected: ${industryType}
Columns: ${csvData.headers.join(', ')}

💰 VALIDATED FINANCIAL METRICS (Calculated from actual data):
${VALIDATED_TOTALS.totalRevenue > 0 ? `Total Revenue: ₹${VALIDATED_TOTALS.totalRevenue.toLocaleString('en-IN')}` : ''}
${VALIDATED_TOTALS.avgRevenue > 0 ? `Average Revenue: ₹${VALIDATED_TOTALS.avgRevenue.toLocaleString('en-IN')}` : ''}
${VALIDATED_TOTALS.totalSpend > 0 ? `Total Spend: ₹${VALIDATED_TOTALS.totalSpend.toLocaleString('en-IN')}` : ''}
${VALIDATED_TOTALS.totalRevenue > 0 && VALIDATED_TOTALS.totalSpend > 0 ? `Profit: ₹${(VALIDATED_TOTALS.totalRevenue - VALIDATED_TOTALS.totalSpend).toLocaleString('en-IN')}` : ''}

${sampleData}

📊 Statistical Summary:
${statisticalResults && !statisticalResults.disabled ? `
- Sample Size: ${statisticalResults.sampleSize} data points
- Mean: ${statisticalResults.mean ? statisticalResults.mean.toFixed(2) : 'N/A'}
- Range: ${statisticalResults.min ? statisticalResults.min.toFixed(2) : 'N/A'} to ${statisticalResults.max ? statisticalResults.max.toFixed(2) : 'N/A'}
` : `- Limited sample size (${rowCount} rows) - showing trends only`}

⚠️ IMPORTANT CONSTRAINTS:
${!growthCheck.allowed ? `- Growth Rate: ${growthCheck.reason}` : ''}
${!statsCheck.allowed ? `- Statistical Tests: ${statsCheck.reason}` : ''}
${!forecastCheck.allowed ? `- Forecasting: ${forecastCheck.reason}` : ''}
`;

    // ============================================
    // BUILD AI SYSTEM PROMPT
    // ============================================
    const systemPrompt = `You are a professional data analyst for ${industryType} industry.

🎯 YOUR TASK:
Analyze the provided dataset and answer the user's question with clear, actionable insights.

📊 VALIDATED DATA (DO NOT RECALCULATE):
${VALIDATED_TOTALS.totalRevenue > 0 ? `Total Revenue: ₹${VALIDATED_TOTALS.totalRevenue.toLocaleString('en-IN')} (VERIFIED)` : ''}
${VALIDATED_TOTALS.avgRevenue > 0 ? `Average Revenue: ₹${VALIDATED_TOTALS.avgRevenue.toLocaleString('en-IN')} (VERIFIED)` : ''}
Sample Size: ${rowCount} data points

⚠️ CRITICAL RULES:
1. Use ONLY the validated totals shown above
2. ${rowCount < 30 ? 'With only ' + rowCount + ' data points, focus on observable trends rather than statistical significance' : 'Provide statistical insights'}
3. ${!growthCheck.allowed ? 'DO NOT calculate growth rates - ' + growthCheck.reason : 'Growth analysis is allowed'}
4. Be specific and actionable
5. If asked about totals, use the VERIFIED values above

📝 RESPONSE FORMAT:
- Start with key finding
- Provide 2-3 actionable insights
- Use bullet points for clarity
- Keep language business-friendly`;

    // ============================================
    // CALL GROQ AI
    // ============================================
    console.log('🤖 Calling GROQ AI...');

    const aiResponse = await fetch(GROQ_API_URL, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${GROQ_API_KEY}`
      },
      body: JSON.stringify({
        model: 'llama-3.3-70b-versatile',
        messages: [
          {
            role: 'system',
            content: systemPrompt
          },
          {
            role: 'user',
            content: `${question}\n\n${dataContext}`
          }
        ],
        temperature: 0.3,
        max_tokens: 2000
      })
    });

    if (!aiResponse.ok) {
      const errorData = await aiResponse.json().catch(() => ({}));
      console.error('❌ AI API Error:', errorData);
      throw new Error(`AI API Error: ${aiResponse.status} - ${errorData.error?.message || 'Unknown error'}`);
    }

    const aiData = await aiResponse.json();
    const answer = aiData.choices[0].message.content;

    console.log('✅ AI Response received');
    console.log('📝 Response length:', answer.length, 'characters');

   // SAVE TO DATABASE (if datasetId provided)
    if (datasetId) {
      try {
        const analysis = new Analysis({
          userId: req.user.uid,
          datasetId: datasetId,
          csvData: {
            headers: csvData.headers,
            data: csvData.data.slice(0, 100), // Save first 100 rows only
            fileName: req.body.fileName || 'dataset.csv'  // ✅ ADDED
          },
          sqlQueries: sqlQueries,  // ✅ ADDED
          analysis: {
            summary: answer,
            metrics: {
              totalRevenue: VALIDATED_TOTALS.totalRevenue,
              avgRevenue: VALIDATED_TOTALS.avgRevenue,
              dataPoints: rowCount,
              growthRate: null
            }
          },
          questions: [{
            question: question,
            answer: answer,
            confidence: 'high',
            timestamp: new Date()
          }],
          industryType: industryType,
          timestamp: new Date()
        });

        await analysis.save();
        console.log('✅ Analysis saved to database with SQL queries');
      } catch (dbError) {
        console.error('⚠️ Failed to save analysis:', dbError.message);
        // Don't fail the request if DB save fails
      }
    }

    // ============================================
    // RETURN COMPLETE RESPONSE
    // ============================================
    res.json({
      success: true,
      type: 'text',
      content: answer,
      confidence: statsCheck.allowed ? 'high' : 'moderate',
      industryType: industryType,
      statistics: statisticalResults,
      availableColumns: availableColumns,
      sqlQueries: sqlQueries,
      validationFlags: {
        growthAllowed: growthCheck.allowed,
        growthReason: growthCheck.reason,
        statsAllowed: statsCheck.allowed,
        statsReason: statsCheck.reason,
        forecastAllowed: forecastCheck.allowed,
        forecastReason: forecastCheck.reason
      },
      validatedTotals: VALIDATED_TOTALS,
      dataQuality: {
        sampleSize: rowCount,
        hasRevenue: VALIDATED_TOTALS.totalRevenue > 0,
        hasSpend: VALIDATED_TOTALS.totalSpend > 0,
        validationWarnings: dataValidation.warnings
      }
    });

    console.log('✅ [ANALYZE] Request completed successfully');

  } catch (error) {
    console.error('❌ [ANALYZE] Error:', error);
    
    // Detailed error logging
    console.error('Error details:', {
      message: error.message,
      stack: error.stack?.split('\n').slice(0, 3).join('\n')
    });

    res.status(500).json({
      success: false,
      error: 'Analysis failed: ' + error.message,
      type: 'error'
    });
  }
});
app.post('/api/compare-analysis', verifyToken, requireMongoDB, async (req, res) => {
  try {
    // âœ… SECURE: Validate request body
    const { currentMetrics, dataType, currentIndustry } = req.body;
    
    if (!currentMetrics || typeof currentMetrics !== 'object') {
      return res.status(400).json({ 
        success: false, 
        error: 'Invalid metrics data' 
      });
    }
    
    // Sanitize industry type
    const sanitizedIndustry = sanitizeMongoInput(currentIndustry);
    const validIndustry = validateDataType(sanitizedIndustry) || 'business';
    
    console.log('ðŸ“Š Fetching historical data for comparison...');
    console.log('ðŸ­ Current Industry:', validIndustry);
    
    if (!currentMetrics) {
      return res.status(400).json({ success: false, error: 'Missing current metrics' });
    }

    console.log('ðŸ“Š Fetching historical data for comparison...');
    console.log('ðŸ­ Current Industry:', currentIndustry || 'unknown');
    
    // Get ALL past analyses
    const allPastAnalyses = await Analysis.find({ 
      userId: req.user.uid 
    })
      .sort({ timestamp: -1 })
      .limit(20)
      .select('analysis.metrics industryType timestamp');

    if (allPastAnalyses.length === 0) {
      console.log('â„¹ï¸ No historical data found for comparison');
      return res.json({
        success: true,
        comparison: {
          hasHistory: false,
          message: 'This is your first analysis. Future analyses will show comparisons!',
          firstTime: true
        }
      });
    }

    console.log(`âœ… Found ${allPastAnalyses.length} total past analyses`);

    // ============================================
    // SMART FILTERING: Only compare SAME industry
    // ============================================
    const sameIndustryAnalyses = allPastAnalyses.filter(a => 
      a.industryType === currentIndustry
    );

    const differentIndustryAnalyses = allPastAnalyses.filter(a => 
      a.industryType !== currentIndustry
    );

    console.log(`ðŸ“Š Same industry (${currentIndustry}): ${sameIndustryAnalyses.length} analyses`);
    console.log(`ðŸ“Š Different industries: ${differentIndustryAnalyses.length} analyses`);

    // Count analyses by industry
    const industryBreakdown = allPastAnalyses.reduce((acc, analysis) => {
      const industry = analysis.industryType || 'unknown';
      if (!acc[industry]) {
        acc[industry] = { count: 0, avgRevenue: 0, analyses: [] };
      }
      acc[industry].count++;
      acc[industry].analyses.push(analysis);
      return acc;
    }, {});

    // Calculate average revenue per industry
    Object.keys(industryBreakdown).forEach(industry => {
      const analyses = industryBreakdown[industry].analyses;
      const validAnalyses = analyses.filter(a => a.analysis?.metrics?.totalRevenue);
      if (validAnalyses.length > 0) {
        industryBreakdown[industry].avgRevenue = 
          validAnalyses.reduce((sum, a) => sum + a.analysis.metrics.totalRevenue, 0) / validAnalyses.length;
      }
    });

    // ============================================
    // CASE 1: NO SAME-INDUSTRY DATA FOUND
    // ============================================
    if (sameIndustryAnalyses.length === 0) {
      console.log('âš ï¸ No same-industry data found for comparison');
      
      const warningMessage = `âš ï¸ **Comparison Not Possible**

I found ${differentIndustryAnalyses.length} past analysis/analyses, but they're from different industries:
${Object.entries(industryBreakdown)
  .filter(([industry]) => industry !== currentIndustry)
  .map(([industry, data]) => `â€¢ ${industry.toUpperCase()}: ${data.count} analysis/analyses`)
  .join('\n')}

**Why can't I compare?**
You're currently analyzing **${currentIndustry.toUpperCase()}** data, but your previous data is from different sectors. Comparing e-commerce with banking, or fintech with retail would give misleading insights because:

1. Different revenue models (products vs services vs transactions)
2. Different metrics (units sold vs active users vs conversions)
3. Different market dynamics and growth patterns
4. Different seasonal trends and business cycles

**What you should do:**
Analyze more **${currentIndustry.toUpperCase()}** datasets to enable meaningful comparisons. Once you have 2+ analyses from the same industry, I'll show you:
- Revenue trends over time
- Growth rate improvements
- Performance benchmarks
- Actionable recommendations

**Your historical data:**
${Object.entries(industryBreakdown).map(([industry, data]) => 
  `â€¢ ${industry}: ${data.count} analyses, Avg Revenue: â‚¹${(data.avgRevenue / 100000).toFixed(2)} lakhs`
).join('\n')}`;

      return res.json({
        success: true,
        comparison: {
          hasHistory: true,
          canCompare: false,
          currentIndustry: currentIndustry,
          sameIndustryCount: 0,
          differentIndustryCount: differentIndustryAnalyses.length,
          industryBreakdown: Object.entries(industryBreakdown).map(([industry, data]) => ({
            industry: industry,
            count: data.count,
            avgRevenue: Math.round(data.avgRevenue)
          })),
          warningMessage: warningMessage,
          aiInsight: warningMessage
        }
      });
    }

    // ============================================
    // CASE 2: SAME-INDUSTRY DATA FOUND - DO COMPARISON
    // ============================================
    console.log(`âœ… Comparing with ${sameIndustryAnalyses.length} same-industry analyses`);

    const validSameIndustryMetrics = sameIndustryAnalyses
      .filter(a => a.analysis?.metrics?.totalRevenue)
      .map(a => a.analysis.metrics);

    if (validSameIndustryMetrics.length === 0) {
      return res.json({
        success: true,
        comparison: {
          hasHistory: true,
          canCompare: false,
          message: 'No valid metrics found in same-industry analyses'
        }
      });
    }

    // Calculate averages from SAME INDUSTRY data only
    const avgPastRevenue = validSameIndustryMetrics.reduce((sum, m) => sum + (m.totalRevenue || 0), 0) / validSameIndustryMetrics.length;
    const avgPastGrowth = validSameIndustryMetrics.reduce((sum, m) => sum + (m.growthRate || 0), 0) / validSameIndustryMetrics.length;
    const avgPastDataPoints = validSameIndustryMetrics.reduce((sum, m) => sum + (m.dataPoints || 0), 0) / validSameIndustryMetrics.length;

    // Calculate percentage changes
    const revenueChange = avgPastRevenue !== 0 
      ? (((currentMetrics.totalRevenue - avgPastRevenue) / avgPastRevenue) * 100).toFixed(2)
      : 0;
    
    const growthChange = avgPastGrowth !== 0
      ? (((currentMetrics.growthRate - avgPastGrowth) / Math.abs(avgPastGrowth)) * 100).toFixed(2)
      : 0;

    // Determine trend
    const trend = parseFloat(revenueChange) > 5 ? 'improving' : 
                  parseFloat(revenueChange) < -5 ? 'declining' : 'stable';

    // Generate AI insight for SAME INDUSTRY comparison
    const comparisonPrompt = `As a ${currentIndustry} business analyst, analyze this SAME-INDUSTRY performance comparison:

**CURRENT ${currentIndustry.toUpperCase()} PERFORMANCE:**
- Total Revenue: â‚¹${currentMetrics.totalRevenue.toLocaleString()} (â‚¹${(currentMetrics.totalRevenue / 100000).toFixed(2)} lakhs)
- Growth Rate: ${currentMetrics.growthRate.toFixed(2)}%
- Data Points: ${currentMetrics.dataPoints}

**HISTORICAL ${currentIndustry.toUpperCase()} AVERAGE (Last ${validSameIndustryMetrics.length} analyses):**
- Average Revenue: â‚¹${avgPastRevenue.toLocaleString()} (â‚¹${(avgPastRevenue / 100000).toFixed(2)} lakhs)
- Average Growth: ${avgPastGrowth.toFixed(2)}%
- Average Data Points: ${Math.round(avgPastDataPoints)}

**CHANGES:**
- Revenue Change: ${revenueChange}% ${parseFloat(revenueChange) > 0 ? 'ðŸ“ˆ UP' : 'ðŸ“‰ DOWN'}
- Growth Change: ${growthChange}%
- Trend: ${trend.toUpperCase()}

${differentIndustryAnalyses.length > 0 ? `
**NOTE:** I found ${differentIndustryAnalyses.length} analyses from other industries (${[...new Set(differentIndustryAnalyses.map(a => a.industryType))].join(', ')}), but I'm ONLY comparing with same-industry (${currentIndustry}) data for accuracy.
` : ''}

Provide a CONCISE ${currentIndustry}-specific insight (3-4 sentences max):
1. Highlight the most significant change
2. Compare against ${currentIndustry} industry benchmarks
3. Give ONE actionable ${currentIndustry}-specific recommendation

Use Indian Rupee lakhs/crores format. Be direct and specific to ${currentIndustry} business.`;

    let aiInsight = '';
    try {
      aiInsight = await callGroqAPI([
        { role: 'system', content: `You are a ${currentIndustry} industry analyst. Focus on ${currentIndustry}-specific insights only.` },
        { role: 'user', content: comparisonPrompt }
      ]);
      console.log('âœ… AI comparison insight generated');
    } catch (error) {
      console.error('âš ï¸ AI insight generation failed:', error.message);
      const revChange = parseFloat(revenueChange);
      aiInsight = `Your ${currentIndustry} revenue is ${trend} with a ${Math.abs(revChange)}% ${revChange > 0 ? 'increase' : 'decrease'} compared to your historical ${currentIndustry} average of â‚¹${(avgPastRevenue / 100000).toFixed(2)} lakhs. ${revChange > 0 ? 'Great progress! Keep focusing on what\'s working.' : 'Consider reviewing your strategy and learning from your better-performing periods.'}`;
    }

    // Add industry context to the insight
    const contextualInsight = differentIndustryAnalyses.length > 0 
      ? `âœ… **Comparing ${currentIndustry.toUpperCase()} data only** (${sameIndustryAnalyses.length} past analyses)\n\n${aiInsight}\n\nðŸ“Š *Note: I found ${differentIndustryAnalyses.length} analyses from other industries but excluded them for accurate comparison.*`
      : `âœ… **${currentIndustry.toUpperCase()} Performance Analysis** (${sameIndustryAnalyses.length} past analyses)\n\n${aiInsight}`;

    const comparisonResult = {
      hasHistory: true,
      canCompare: true,
      currentIndustry: currentIndustry,
      sameIndustryCount: sameIndustryAnalyses.length,
      differentIndustryCount: differentIndustryAnalyses.length,
      trend: trend,
      pastAnalysesCount: validSameIndustryMetrics.length,
      metrics: {
        current: {
          totalRevenue: currentMetrics.totalRevenue,
          growthRate: currentMetrics.growthRate,
          dataPoints: currentMetrics.dataPoints
        },
        pastAverage: {
          totalRevenue: Math.round(avgPastRevenue),
          growthRate: parseFloat(avgPastGrowth.toFixed(2)),
          dataPoints: Math.round(avgPastDataPoints)
        },
        changes: {
          revenueChange: revenueChange,
          growthChange: growthChange
        }
      },
      industryBreakdown: Object.entries(industryBreakdown).map(([industry, data]) => ({
        industry: industry,
        count: data.count,
        avgRevenue: Math.round(data.avgRevenue),
        isCurrent: industry === currentIndustry
      })),
      aiInsight: contextualInsight
    };

    console.log('âœ… Same-industry comparison complete');
    console.log(`ðŸ“ˆ ${currentIndustry} Trend: ${trend}, Revenue Change: ${revenueChange}%`);
    if (differentIndustryAnalyses.length > 0) {
      console.log(`â„¹ï¸ Excluded ${differentIndustryAnalyses.length} different-industry analyses`);
    }

    res.json({
      success: true,
      comparison: comparisonResult
    });

  } catch (error) {
    handleError(res, error, 'Failed to generate comparison');
  }
});


// ============================================
// CONVERSATIONAL AI DATA SCIENTIST ENDPOINT (USING GROQ)
// ============================================
app.post('/api/chat-analyze', verifyToken, async (req, res) => {
  try {
    const { message, conversationHistory } = req.body;

    console.log('💬 Conversational analysis request:', message);

    // Step 1: Extract data from natural language using GROQ
    const extractionPrompt = `You are a data extraction specialist. Extract all numerical data, metrics, and business information from the following text and convert it to CSV format.

User message: "${message}"

Extract and structure as CSV with these rules:
1. Create appropriate column headers (Metric, Value, Unit, Category, Region, etc.)
2. Each piece of data should be a row
3. Preserve all numbers, percentages, dates, and categories
4. Return ONLY valid CSV, no markdown, no explanations

Example format:
Metric,Value,Unit,Category,Region
Product A Price Official,120,USD/month,Product,Global
Product A Price Actual Min,82,USD/month,Product,Global
Product A Price Actual Max,95,USD/month,Product,Global
Churn Rate Overall,4.1,percent,KPI,Global
Churn Rate SMB,6.5,percent,KPI,SMB

CSV:`;

    // Call GROQ for extraction
    let extractedCSV;
    try {
      extractedCSV = await callGroqAPI([
        { role: 'system', content: 'You are a data extraction expert. Return ONLY CSV format, no markdown, no explanations.' },
        { role: 'user', content: extractionPrompt }
      ]);
      
      // Clean the CSV
      extractedCSV = extractedCSV
        .replace(/```csv\n?/g, '')
        .replace(/```\n?/g, '')
        .trim();
      
    } catch (error) {
      console.error('CSV extraction error:', error);
      extractedCSV = 'Metric,Value,Unit\nData Extraction,Failed,N/A';
    }

    console.log('📊 Extracted CSV:', extractedCSV.substring(0, 200) + '...');

    // Step 2: Parse CSV into structured format
    const csvLines = extractedCSV.split('\n').filter(line => line.trim());
    
    if (csvLines.length < 2) {
      return res.json({
        success: true,
        conversation: {
          userMessage: message,
          aiResponse: "I understand your situation, but I couldn't extract enough structured data from your message. Could you provide some specific numbers or metrics I can analyze?"
        },
        extractedData: null,
        timestamp: new Date().toISOString()
      });
    }

    const headers = csvLines[0].split(',').map(h => h.trim().replace(/"/g, ''));
    const data = csvLines.slice(1).map(line => {
      return line.split(',').map(cell => {
        const cleaned = cell.trim().replace(/"/g, '');
        const num = parseFloat(cleaned.replace(/[$,₹%]/g, ''));
        return isNaN(num) ? cleaned : num;
      });
    });

    const csvData = { headers, data };

    console.log(`✅ Parsed ${data.length} rows with ${headers.length} columns`);

    // Step 3: Industry Detection & Metrics
    const availableColumns = detectAvailableMetrics(headers);
    const industryType = detectIndustryType(availableColumns);
    const schemaMetrics = generateIndustryMetrics(csvData, industryType, availableColumns);

    console.log('🎯 Detected Industry:', industryType);

    // Step 4: Advanced Statistical Analysis
    let statisticalResults = null;
    
    const valueColumn = headers.findIndex(h => 
      h.toLowerCase().includes('value') || 
      h.toLowerCase().includes('amount') ||
      h.toLowerCase().includes('revenue') ||
      h.toLowerCase().includes('price')
    );

    if (valueColumn >= 0) {
      const values = data
        .map(row => parseFloat(row[valueColumn]))
        .filter(val => !isNaN(val) && isFinite(val));

      if (values.length >= 10) {
        const AdvancedStatistics = require('./utils/advancedStats');
        const stats = new AdvancedStatistics(values, headers[valueColumn]);
        statisticalResults = stats.getFullAnalysis();
        console.log('✅ Statistical analysis complete');
      } else {
        statisticalResults = {
          disabled: true,
          reason: `Only ${values.length} numeric values found (need 10+)`,
          sampleSize: values.length
        };
      }
    }

    // Step 5: Calculate Basic Metrics
    // Calculate metrics from csvData
    const metrics = {
      totalRows: data.length,
      totalColumns: headers.length,
      totalRevenue: schemaMetrics['Total Revenue'] ? parseFloat(schemaMetrics['Total Revenue']) : 0,
      avgRevenue: schemaMetrics['Average Revenue'] ? parseFloat(schemaMetrics['Average Revenue']) : 0,
      dataPoints: data.length,
      growthRate: null, // Will be calculated if date column exists
      industryType: industryType
    };
    
    // Calculate growth rate if we have a date column
    const dateCol = headers.findIndex(h => 
      h.toLowerCase().includes('date') || 
      h.toLowerCase().includes('month') || 
      h.toLowerCase().includes('year')
    );
    
    const revenueCol = headers.findIndex(h => 
      h.toLowerCase().includes('revenue') || 
      h.toLowerCase().includes('sales') || 
      h.toLowerCase().includes('amount')
    );
    
    if (dateCol >= 0 && revenueCol >= 0 && data.length >= 2) {
      const firstRevenue = parseFloat(data[0][revenueCol]) || 0;
      const lastRevenue = parseFloat(data[data.length - 1][revenueCol]) || 0;
      
      if (firstRevenue > 0) {
        metrics.growthRate = ((lastRevenue - firstRevenue) / firstRevenue) * 100;
      }
    }

    // Step 6: Prepare Chart Data
    // Prepare chart data from csvData
    const chartData = {
      hasCharts: false,
      charts: []
    };
    
    // Try to create basic charts if we have time-series data
    const dateColChart = headers.findIndex(h => 
      h.toLowerCase().includes('date') || 
      h.toLowerCase().includes('month') || 
      h.toLowerCase().includes('year') ||
      h.toLowerCase().includes('time')
    );
    
    const valueColChart = headers.findIndex(h => 
      h.toLowerCase().includes('value') || 
      h.toLowerCase().includes('revenue') || 
      h.toLowerCase().includes('amount') ||
      h.toLowerCase().includes('sales')
    );
    
    if (dateColChart >= 0 && valueColChart >= 0 && data.length > 0) {
      chartData.hasCharts = true;
      chartData.charts.push({
        type: 'line',
        title: `${headers[valueColChart]} Over Time`,
        data: data.map(row => ({
          x: row[dateColChart],
          y: parseFloat(row[valueColChart]) || 0
        }))
      });
    }
    
    // Add category distribution if we have categorical data
    const categoryColChart = headers.findIndex(h => 
      h.toLowerCase().includes('category') || 
      h.toLowerCase().includes('type') || 
      h.toLowerCase().includes('status')
    );
    
    if (categoryColChart >= 0 && valueColChart >= 0) {
      const categoryDataChart = {};
      data.forEach(row => {
        const category = row[categoryColChart];
        const value = parseFloat(row[valueColChart]) || 0;
        categoryDataChart[category] = (categoryDataChart[category] || 0) + value;
      });
      
      chartData.charts.push({
        type: 'bar',
        title: `${headers[valueColChart]} by ${headers[categoryColChart]}`,
        data: Object.entries(categoryDataChart).map(([category, value]) => ({
          category,
          value
        }))
      });
    }

    // Step 7: Generate SQL Documentation
    const sqlQueries = generateValidatedSQL(csvData, schemaMetrics, availableColumns);

    // Step 8: Generate Comprehensive Business Insights using GROQ
    const dataContext = `
📊 EXTRACTED DATA ANALYSIS
Industry: ${industryType}
Total Data Points: ${data.length}
Columns: ${headers.join(', ')}

📋 DATA SAMPLE:
${headers.join(' | ')}
${data.slice(0, 10).map(row => row.join(' | ')).join('\n')}
${data.length > 10 ? `\n... (${data.length - 10} more rows)` : ''}

📈 KEY METRICS:
${metrics ? `
- Total Revenue: ₹${metrics.totalRevenue?.toLocaleString() || 'N/A'}
- Average: ₹${metrics.avgRevenue?.toLocaleString() || 'N/A'}
- Growth Rate: ${metrics.growthRate?.toFixed(2) || 'N/A'}%
- Data Points: ${metrics.dataPoints}
` : 'Metrics calculation in progress...'}

📊 STATISTICAL SUMMARY:
${statisticalResults && !statisticalResults.disabled ? `
- Sample Size: ${statisticalResults.sampleSize}
- Mean: ${statisticalResults.mean?.toFixed(2)}
- Median: ${statisticalResults.median?.toFixed(2)}
- Std Dev: ${statisticalResults.standardDeviation?.toFixed(2)}
- Outliers (IQR): ${statisticalResults.outliersIQR?.count || 0}
` : 'Limited statistical analysis available'}
`;

    const insightPrompt = `You are a professional ${industryType} business analyst. Analyze this data and provide actionable insights.

${dataContext}

ORIGINAL CONTEXT:
${message.substring(0, 1000)}...

Provide a comprehensive analysis in this structure:

**🎯 KEY FINDINGS**
- 3-5 most critical insights from the data
- Focus on actionable patterns

**📊 STATISTICAL INTERPRETATION**
- What the numbers reveal about business health
- Trends and patterns

**⚠️ RISK ANALYSIS**
- What could go wrong
- Red flags in the data

**💡 PRIORITIZED RECOMMENDATIONS**
1. Urgent actions (do immediately)
2. Important actions (this quarter)
3. Long-term improvements

**📈 NEXT STEPS**
- Specific, measurable actions

Use Indian Rupee format (lakhs/crores). Be specific and executive-ready.`;

    const insightResponse = await callGroqAPI([
      ...(conversationHistory || []).slice(-3).map(msg => ({
        role: msg.role,
        content: msg.content
      })),
      { role: 'user', content: insightPrompt }
    ]);

    console.log('✅ AI insights generated');

    // Step 9: Return Complete Analysis
    res.json({
      success: true,
      conversation: {
        userMessage: message,
        aiResponse: insightResponse
      },
      // Same data structure as /api/analyze
      csvData: csvData,
      metrics: metrics,
      charts: chartData,
      statistics: statisticalResults,
      schemaMetrics: schemaMetrics,
      availableColumns: availableColumns,
      sqlQueries: sqlQueries,
      industryType: industryType,
      extractedCSV: extractedCSV,
      timestamp: new Date().toISOString()
    });

  } catch (error) {
    console.error('❌ Chat analysis error:', error);
    res.status(500).json({
      success: false,
      error: error.message
    });
  }
});
// ============================================
// TEXT TO DATA EXTRACTION ENDPOINT (USING GROQ)
// ============================================
app.post('/api/extract-data', verifyToken, async (req, res) => {
  try {
    const { text } = req.body;

    const extractionPrompt = `Extract all numerical data from this business conversation and convert it to CSV format.

Text: "${text}"

Rules:
1. Find all metrics, prices, percentages, dates
2. Create appropriate column headers
3. Each metric should be a row
4. Return ONLY CSV format, no explanation, no markdown

Example output:
Metric,Value,Unit,Context
Product A Price,120,USD/month,Official
Product A Actual,82-95,USD/month,Realized
Churn Rate,4.1,percent,Monthly`;

    const csvResponse = await callGroqAPI([
      { role: 'system', content: 'Return ONLY CSV format, no markdown, no explanations.' },
      { role: 'user', content: extractionPrompt }
    ]);

    const cleanedCSV = csvResponse
      .replace(/```csv\n?/g, '')
      .replace(/```\n?/g, '')
      .trim();

    res.json({
      success: true,
      csvData: cleanedCSV,
      message: 'Data extracted and converted to CSV'
    });

  } catch (error) {
    console.error('❌ Data extraction error:', error);
    res.status(500).json({
      success: false,
      error: error.message
    });
  }
});

// ============================================
// CONVERSATIONAL QUERY ENDPOINT (Talk to AI Mode)
// ============================================
app.post('/api/query', upload.single('file'), async (req, res) => {
  let filePath = null;
  
  try {
    const { query, conversationHistory } = req.body;
    const file = req.file;

    if (!file) {
      return res.status(400).json({ error: 'No file uploaded' });
    }

    filePath = file.path;
    console.log(`📊 Processing query with file: ${file.originalname}`);

    // Parse CSV
    const csv = require('csv-parser');
    const results = [];

    await new Promise((resolve, reject) => {
      fs.createReadStream(filePath)
        .pipe(csv())
        .on('data', (data) => results.push(data))
        .on('end', resolve)
        .on('error', reject);
    });

    // Clean up file
    fs.unlinkSync(filePath);

    if (results.length === 0) {
      return res.status(400).json({ error: 'Empty CSV file' });
    }

    // Get schema information
    const columns = Object.keys(results[0]);
    const sampleData = results.slice(0, 5);
    
    // Analyze data types and statistics
    const columnStats = {};
    const numericColumns = [];
    
    columns.forEach(col => {
      const values = results.map(row => row[col]).filter(v => v !== null && v !== undefined && v !== '');
      const numericValues = values.map(v => parseFloat(v)).filter(v => !isNaN(v));
      
      if (numericValues.length > values.length * 0.8) {
        numericColumns.push(col);
        columnStats[col] = {
          type: 'numeric',
          min: Math.min(...numericValues),
          max: Math.max(...numericValues),
          mean: numericValues.reduce((a, b) => a + b, 0) / numericValues.length,
          count: numericValues.length
        };
      } else {
        const uniqueValues = [...new Set(values)];
        columnStats[col] = {
          type: 'categorical',
          uniqueCount: uniqueValues.length,
          sampleValues: uniqueValues.slice(0, 5),
          count: values.length
        };
      }
    });

    // Detect industry and generate metrics
    const availableColumns = detectAvailableMetrics(columns);
    const industryType = detectIndustryType(availableColumns);
    
    // Convert to csvData format for schema analysis
    const csvData = {
      headers: columns,
      data: results.map(row => columns.map(col => {
        const val = row[col];
        const num = parseFloat(val);
        return isNaN(num) ? val : num;
      }))
    };
    
    const schemaMetrics = generateIndustryMetrics(csvData, industryType, availableColumns);
    const sqlQueries = generateValidatedSQL(csvData, schemaMetrics, availableColumns);

    // Create schema summary for AI
    const schemaSummary = `
Dataset Schema:
- Total Rows: ${results.length}
- Columns: ${columns.join(', ')}
- Industry: ${industryType}

Column Details:
${columns.map(col => {
  const stats = columnStats[col];
  if (stats.type === 'numeric') {
    return `- ${col} (Numeric): Range ${stats.min.toFixed(2)} to ${stats.max.toFixed(2)}, Mean: ${stats.mean.toFixed(2)}`;
  } else {
    return `- ${col} (Categorical): ${stats.uniqueCount} unique values (e.g., ${stats.sampleValues.join(', ')})`;
  }
}).join('\n')}

Sample Data:
${JSON.stringify(sampleData, null, 2)}
`;

    // Build conversation context
    const messages = [
      {
        role: 'user',
        content: `You are a data analyst assistant. You have access to a CSV dataset with the following schema:

${schemaSummary}

When answering questions:
1. Provide insights based on the actual data
2. Reference specific columns and statistics
3. Suggest relevant analyses or visualizations
4. Be concise but informative

User Question: ${query}`
      }
    ];

    // Add conversation history
    if (conversationHistory && conversationHistory.length > 0) {
      conversationHistory.forEach(msg => {
        messages.push({
          role: msg.role,
          content: msg.content
        });
      });
      messages.push({
        role: 'user',
        content: query
      });
    }

    // Call GROQ API
    const aiResponse = await callGroqAPI(messages);

    // Return response with schema info
    res.json({
      response: aiResponse,
      schema: {
        columns: columns,
        rowCount: results.length,
        columnStats: columnStats,
        numericColumns: numericColumns,
        sampleData: sampleData
      },
      metrics: {
        totalRows: results.length,
        totalColumns: columns.length,
        numericColumns: numericColumns.length,
        categoricalColumns: columns.length - numericColumns.length
      },
      schemaMetrics: schemaMetrics,
      availableColumns: availableColumns,
      sqlQueries: sqlQueries,
      industryType: industryType
    });

  } catch (error) {
    console.error('❌ Query error:', error);
    
    // Cleanup file on error
    if (filePath && fs.existsSync(filePath)) {
      fs.unlinkSync(filePath);
    }
    
    res.status(500).json({ 
      error: 'Error processing query',
      details: error.message 
    });
  }
});
// ============================================
// Serve React Frontend (works in all environments)
// ============================================
const buildPath = path.join(__dirname, '..', 'frontend', 'build');
if (fs.existsSync(buildPath)) {
  console.log('ðŸ“¦ Serving frontend from:', buildPath);
  
  // Serve static files (CSS, JS, images)
  app.use(express.static(buildPath));
  
  // API info endpoint (accessible at /api)
  app.get('/api', (req, res) => {
    res.json({
      message: 'ðŸš€ InsightAI Backend API',
      status: 'running',
      version: '1.0.0',
      timestamp: new Date().toISOString(),
      endpoints: {
        health: '/api/health',
        demoDatasets: '/api/demo-datasets',
        uploadFile: '/api/upload-file',
        parseData: '/api/parse-data',
        analyze: '/api/analyze',
        saveAnalysis: '/api/save-analysis',
        analysisHistory: '/api/analysis-history',
        compareAnalysis: '/api/compare-analysis'
      },
      docs: 'https://github.com/Druv12/insightai',
      frontend: 'https://insightais.onrender.com'
    });
  });
  
  // Serve React app for all non-API routes (THIS MUST BE LAST)
  app.get('*', (req, res) => {
    if (!req.path.startsWith('/api')) {
      res.sendFile(path.join(buildPath, 'index.html'));
    }
  });
} else {
  console.log('âš ï¸ Frontend build folder not found. Run: cd frontend && npm run build');
}

// Start server
app.listen(PORT, () => {
  console.log(`ðŸš€ InsightAI Backend - Universal Analytics Platform`);
  console.log(`ðŸ“ Server running on port ${PORT}`);
  console.log(`ðŸŒ Environment: ${process.env.NODE_ENV || 'development'}`);
  console.log(`ðŸ“Š MongoDB: ${mongoose.connection.readyState === 1 ? 'âœ… Connected' : 'âš ï¸ Disconnected'}`);
});

// ============================================
// GRACEFUL SHUTDOWN
// ============================================
const gracefulShutdown = async () => {
  console.log('ðŸ‘‹ Shutting down gracefully...');
  
  try {
    await mongoose.connection.close();
    console.log('âœ… MongoDB connection closed');
  } catch (error) {
    console.error('âŒ Error closing MongoDB:', error);
  }
  
  process.exit(0);
};

process.on('SIGTERM', gracefulShutdown);
process.on('SIGINT', gracefulShutdown);
